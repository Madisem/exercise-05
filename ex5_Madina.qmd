---
title: "exercise-05"
author: "Madina"
format: html
editor: visual
---

## Running Code

### **Step 1**

-   Using the {tidyverse} `read_csv()` function, load the “IMDB-movies.csv” dataset from [this URL](https://raw.githubusercontent.com/difiore/ada-datasets/main/IMDB-movies.csv) as a “tibble” named **d**

```{r}

library(tidyverse)
mv<-read_csv("IMDB-movies.csv", col_names = TRUE)
mv
```

### **Step 2**

-   Use a one-line statement to filter the dataset to include just movies from 1920 to 1979 and movies that are between 1 and 3 hours long (**runtimeMinutes** \>= 60 and **runtimeMinutes** \<= 180), and add a new column that codes the **startYear** into a new variable, **decade** (“20s”, “30s”, …“70s”). If you do this correctly, there should be 5651 movies remaining in the dataset.

> **HINT:** Use {dplyr} functions and the pipe operator!

```{r}
library(dplyr)
  mv_filt <- mv |> filter(startYear>=1920 & startYear <= 1979) |> filter(runtimeMinutes >=60 & runtimeMinutes <=180) |> 
    mutate(decade=case_when( startYear >=1920 & startYear < 1930 ~ "20s", 
                            startYear >= 1930 & startYear < 1940 ~ "30s",
                            startYear >= 1940 & startYear < 1950 ~ "40s",
                            startYear >= 1950 & startYear < 1960 ~ "50s",
                            startYear >= 1960 & startYear < 1970 ~ "60s",
                            startYear >= 1970 & startYear < 1980 ~ "70s"))
  
  mv_filt
```

### **Step 3**

-   Use {ggplot2} (which is part of {tidyverse}) to plot histograms of the distribution of **runtimeMinutes** for each decade.

> **HINT:** Try using `facet_wrap()` to do this!

```{r}
ggplot(data=mv_filt, mapping = aes(x=runtimeMinutes))+
  geom_histogram(binwidth = 4, color = "orange", alpha = 0.7)+
  labs(x = "Movie Runtime")+
  facet_wrap(~decade, ncol=2)
```

### **Step 4**

-   Use a one-line statement to calculate the population mean and population standard deviation in **runtimeMinutes**for each decade and save the results in a new dataframe called **results**.

```{r}
results<-mv_filt |> group_by(decade) |> summarise(mean=mean(runtimeMinutes),std=sd(runtimeMinutes))
results

```

### **Step 5**

-   Draw a single sample of 100 movies, without replacement, from each decade and calculate the single sample mean and single sample standard deviation in **runtimeMinutes** for each decades. Recall that your single sample mean for each decade is an *estimate* of the population mean for each decade.

```{r}

result_100<- slice_sample(mv_filt,n = 100,by = decade) |> group_by(decade) |> summarise(estimate=mean(runtimeMinutes),std=sd(runtimeMinutes))
  
result_100  
  
 
```

### **Step 6**

-   Calculate for each decade the standard error around your estimate of the population mean **runtimeMinutes** based on the standard deviation and sample size (n=100 movies) of your single sample.

```{r}
result_100_se<- slice_sample(mv_filt,n = 100,by = decade) |> group_by(decade) |> summarise(estimate=mean(runtimeMinutes),std=sd(runtimeMinutes), se=std/sqrt(100))

result_100_se
```

### **Step 7**

-   Compare these estimates to the actual population mean **runtimeMinutes** for each decade and to the calculated SE in the population mean for samples of size 100 based on the population standard deviation for each decade.

actual population mean runtimeMinutes for each decade was saved into 'results' dataframe! for comparison inner joining the two dataframe.

```{r}
inner_join(results, result_100_se, by = "decade")

```

### **Step 8**

-   Generate a *sampling distribution* of mean **runtimeMinutes** for each decade by \[a\] drawing 1000 random samples of 100 movies from each decade, without replacement, and, for each sample, \[b\] calculating the mean **runtimeMinutes** and the standard deviation in **runtimeMinutes** for each decade. Use either a standard `for( ){ }` loop, the `do(reps) *` formulation from {mosaic}, the `rerun()` function from {purrr}, or the `rep_sample_n()` workflow from {infer} to generate your these sampling distributions (see [**Module 16**](https://difiore.github.io/ada-2025/16-module.html)).

```{r}
library(infer)
 
sample_distr_list <- data.frame()

for (dec in unique(mv_filt$decade)) {
  decade_data <- mv_filt |> filter(decade == dec)
  sample_distr <- decade_data |> rep_sample_n(size=100,reps = 1000,replace = FALSE) |> summarise(mean=mean(runtimeMinutes),std=sd(runtimeMinutes))
#  sample_distr_list[[dec]] <- sample_distr

  sample_distr <- sample_distr |> mutate(decade = dec)

   sample_distr_list <- bind_rows(sample_distr_list, sample_distr)
}

sample_distr_list
```

### **Step 9**

-   Then, calculate the **mean** and the **standard deviation** of the sampling distribution of sample means for each decade (the former should be a very good estimate of the population mean, while the latter is another estimate of the standard error in our estimate of the population mean for a particular sample size) and plot a histogram of the sampling distribution for each decade. What shape does it have?

```{r}

mean_std_1000_decade <- sample_distr_list |> group_by(decade) |> 
  summarise(mean_of_means = mean(mean), std_of_means = sd(mean))
 
mean_std_1000_decade

ggplot(sample_distr_list, aes(x = mean, fill = factor(decade))) +
  geom_histogram(binwidth = 2, color = "black", alpha = 0.5) +
  facet_wrap(~decade, ncol = 3) +
  labs(title = "Sampling Distribution of Mean Runtime by Decade",
       x = "Mean Runtime (minutes)",
       y = "Frequency",
       fill = "Decade")
```

### **Step 10**

-   Finally, compare the standard error in **runtimeMinutes** for samples of size 100 from each decade \[1\] as estimated from your **first** sample of 100 movies, \[2\] as calculated from the known *population* standard deviations for each decade, and \[3\] as estimated from the sampling distribution of sample means for each decade.

```{r}

result_100_se<-slice_sample(mv_filt,n = 100,by = decade) |> group_by(decade) |> summarise(mean_sample=mean(runtimeMinutes),std_sample=sd(runtimeMinutes), se_sample=std_sample/sqrt(100))

result_100_se
population<-mv_filt |> group_by(decade) |> summarise(mean=mean(runtimeMinutes),std_pop=sd(runtimeMinutes), se_pop=std_pop/sqrt(length(runtimeMinutes)))
population

se_sampling_distr <- sample_distr_list |> group_by(decade) |> 
  summarise(mean_distr = mean(mean), std_distr = sd(mean), se_distr=std_distr/sqrt(length(mean)))

se_sampling_distr

inner_join(result_100_se, population, se_sampling_distr, by = "decade")# |> select(decade, 3,6,9)

final_table <- result_100_se |> 
  inner_join(population, by = "decade") |> 
  inner_join(se_sampling_distr, by = "decade") |> 
  select(decade, 4, 7, 10)

final_table

                                         
                                          
                                                     
                                      
```
